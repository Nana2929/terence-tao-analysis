\section{Partial and directional derivatives}\label{sec 6.3}

\begin{definition}[Directional derivative]\label{6.3.1}
    Let \(E\) be a subset of \(\mathbf{R}^n\), \(f : E \to \mathbf{R}^m\) be a function, let \(x_0\) be an interior point of \(E\), and let \(v\) be a vector in \(\mathbf{R}^n\).
    If the limit
    \[
        \lim_{t \to 0 ; t > 0, x_0 + tv \in E} \frac{f(x_0 + tv) - f(x_0)}{t}
    \]
    exists, we say that \(f\) is \emph{differentiable in the direction \(v\) at \(x_0\)}, and we denote the above limit by \(D_v f(x_0)\):
    \[
        D_v f(x_0) \coloneqq \lim_{t \to 0 ; t > 0, x_0 + tv \in E} \frac{f(x_0 + tv) - f(x_0)}{t}.
    \]
\end{definition}

\begin{remark}\label{6.3.2}
    One should compare Definition \ref{6.3.1} with Definition \ref{6.2.2}.
    Note that we are dividing by a scalar \(t\), rather than a vector, so this definition makes sense, and \(D_v f(x_0)\) will be a vector in \(\mathbf{R}^m\).
    It is sometimes possible to also define directional derivatives on the boundary of \(E\), if the vector \(v\) is pointing in an ``inward'' direction
    (this generalizes the notion of left derivatives and right derivatives from single variable calculus);
    but we will not pursue these matters here.
\end{remark}

\begin{example}\label{6.3.3}
    If \(f : \mathbf{R} \to \mathbf{R}\) is a function, then \(D_{+1} f(x)\) is the same as the right derivative of \(f(x)\) (if it exists), and similarly \(D_{-1} f(x)\) is the same as the negative of the left derivative of \(f(x)\) (if it exists).
\end{example}

\begin{proof}
    We have
    \begin{align*}
        D_{+1} f(x) & = \lim_{t \to 0 ; t > 0} \frac{f(x_0 + t) - f(x_0)}{t}                           & \text{(by Definition \ref{6.3.1})} \\
                    & = \lim_{x \to x_0 ; x > x_0} \frac{f\big(x_0 + (x - x_0)\big) - f(x_0)}{x - x_0}                                      \\
                    & = \lim_{x \to x_0 ; x > x_0} \frac{f(x) - f(x_0)}{x - x_0}                                                            \\
                    & = f(x_0+)
    \end{align*}
    and
    \begin{align*}
        D_{-1} f(x) & = \lim_{t \to 0 ; t > 0} \frac{f(x_0 - t) - f(x_0)}{t}                           & \text{(by Definition \ref{6.3.1})} \\
                    & = \lim_{x \to x_0 ; x < x_0} \frac{f\big(x_0 - (x_0 - x)\big) - f(x_0)}{x_0 - x}                                      \\
                    & = \lim_{x \to x_0 ; x < x_0} \frac{f(x) - f(x_0)}{x_0 - x}                                                            \\
                    & = -\lim_{x \to x_0 ; x < x_0} \frac{f(x) - f(x_0)}{x - x_0}                                                           \\
                    & = -f(x_0-).
    \end{align*}
\end{proof}

\setcounter{theorem}{4}
\begin{lemma}\label{6.3.5}
    Let \(E\) be a subset of \(\mathbf{R}^n\), \(f : E \to \mathbf{R}^m\) be a function, \(x_0\) be an interior point of \(E\), and let \(v\) be a vector in \(\mathbf{R}^n\).
    If \(f\) is differentiable at \(x_0\), then \(f\) is also differentiable in the direction \(v\) at \(x_0\), and
    \[
        D_v f(x_0) = f'(x_0)(v).
    \]
\end{lemma}

\begin{proof}
    Since \(f\) is differentiable at \(x_0\), by Definition \ref{6.2.2} we know that \(f'(x_0) : \mathbf{R}^n \to \mathbf{R}^m\) exists and \(f'(x_0)\) is a linear transformation.
    If \(v = 0_{\mathbf{R}^n}\), then we have
    \begin{align*}
         & f'(x_0)(0_{\mathbf{R}^n})                                                                                                                             \\
         & = 0_{\mathbf{R}^m}                                                                                      & \text{(cf. the proof of Lemma \ref{6.2.4})} \\
         & = \lim_{t \to 0 ; t > 0, x_0 + t 0_{\mathbf{R}^n} \in E} \frac{f(x_0 + t 0_{\mathbf{R}^n}) - f(x_0)}{t}                                               \\
         & = D_{0_{\mathbf{R}^n}} f(x_0).                                                                          & \text{(by Definition \ref{6.3.1})}
    \end{align*}
    So suppose that \(v \neq 0_{\mathbf{R}^n}\).
    Then we have
    \begin{align*}
                 & \lim_{x \to x_0 ; x \in E \setminus \{x_0\}} \frac{\norm*{f(x) - f(x_0) - f'(x_0)(x - x_0)}}{\norm*{x - x_0}} = 0                                  \\
        \implies & \lim_{t \to 0 ; t > 0, x_0 + tv \in E \setminus \{x_0\}} \frac{\norm*{f(x_0 + tv) - f(x_0) - f'(x_0)(x_0 + tv - x_0)}}{\norm*{x_0 + tv - x_0}} = 0 \\
        \implies & \lim_{t \to 0 ; t > 0, x_0 + tv \in E \setminus \{x_0\}} \frac{\norm*{f(x_0 + tv) - f(x_0) - f'(x_0)(tv)}}{\norm*{tv}} = 0                         \\
        \implies & \lim_{t \to 0 ; t > 0, x_0 + tv \in E \setminus \{x_0\}} \frac{\norm*{t \frac{f(x_0 + tv) - f(x_0)}{t} - f'(x_0)(tv)}}{\norm*{tv}} = 0             \\
        \implies & \lim_{t \to 0 ; t > 0, x_0 + tv \in E \setminus \{x_0\}} \frac{\norm*{t \frac{f(x_0 + tv) - f(x_0)}{t} - t f'(x_0)(v)}}{\norm*{tv}} = 0            \\
        \implies & \lim_{t \to 0 ; t > 0, x_0 + tv \in E \setminus \{x_0\}} \frac{t \norm*{\frac{f(x_0 + tv) - f(x_0)}{t} - f'(x_0)(v)}}{t \norm*{v}} = 0             \\
        \implies & \lim_{t \to 0 ; t > 0, x_0 + tv \in E \setminus \{x_0\}} \frac{\norm*{\frac{f(x_0 + tv) - f(x_0)}{t} - f'(x_0)(v)}}{\norm*{v}} = 0                 \\
        \implies & \lim_{t \to 0 ; t > 0, x_0 + tv \in E \setminus \{x_0\}} \norm*{\frac{f(x_0 + tv) - f(x_0)}{t} - f'(x_0)(v)} = 0                                   \\
        \implies & \lim_{t \to 0 ; t > 0, x_0 + tv \in E \setminus \{x_0\}} \frac{f(x_0 + tv) - f(x_0)}{t} = f'(x_0)(v)                                               \\
        \implies & D_v f(x_0) = f'(x_0)(v).
    \end{align*}
    Thus we conclude that
    \[
        f'(x_0) \text{ exists } \implies \forall\ v \in \mathbf{R}^n, D_v f(x_0) = f'(x_0)(v).
    \]
\end{proof}

\begin{remark}\label{6.3.6}
    One consequence of Lemma \ref{6.3.5} is that total differentiability implies directional differentiability.
    However, the converse is not true;
    see Exercise \ref{ex 6.3.3}.
\end{remark}

\begin{definition}[Partial derivative]\label{6.3.7}
    Let \(E\) be a subset of \(\mathbf{R}^n\), let \(f : E \to \mathbf{R}^m\) be a function, let \(x_0\) be an interior point of \(E\), and let \(1 \leq j \leq n\).
    Then the \emph{partial derivative of \(f\) with respect to the \(x_j\) variable} at \(x_0\), denoted \(\frac{\partial f}{\partial x_j}(x_0)\), is defined by
    \[
        \frac{\partial f}{\partial x_j}(x_0) \coloneqq \lim_{t \to 0 ; t \neq 0, x_0 + t e_j \in E} \frac{f(x_0 + t e_j) - f(x_0)}{t} = \frac{d}{dt} f(x_0 + t e_j)|_{t = 0}
    \]
    provided of course that the limit exists.
    (If the limit does not exist, we leave \(\frac{\partial f}{\partial x_j}(x_0)\) undefined).
\end{definition}

\begin{additional corollary}\label{ac 6.3.1}
Informally, the partial derivative can be obtained by holding all the variables other than \(x_j\) fixed, and then applying the single-variable calculus derivative in the \(x_j\) variable.
Note that if \(f\) takes values in \(\mathbf{R}^m\), then so will \(\frac{\partial f}{\partial x_j}\).
Indeed, if we write \(f\) in components as \(f = (f_1, \dots, f_m)\), it is easy to see (by Proposition \ref{1.1.18}) that
\[
    \frac{\partial f}{\partial x_j}(x_0) = \bigg(\frac{\partial f_1}{\partial x_j}(x_0), \dots, \frac{\partial f_m}{\partial x_j}(x_0)\bigg)
\]
i.e., to differentiate a vector-valued function one just has to differentiate each of the components separately.
\end{additional corollary}

\begin{note}
    We sometimes replace the variables \(x_j\) in \(\frac{\partial f}{\partial x_j}\) with other symbols.
    One should caution however that one should only relabel the variables if it is absolutely clear which symbol refers to the first variable, which symbol refers to the second variable, etc.;
    otherwise one may become unintentionally confused.
    The operation of total differentiation \(\frac{d}{dx}\) is not the same as that of partial differentiation \(\frac{\partial}{\partial x}\).
\end{note}

\begin{additional corollary}\label{ac 6.3.2}
From Lemma \ref{6.3.5} (and Proposition 9.5.3 from Analysis I), we know that if a function is differentiable at a point \(x_0\), then all the partial derivatives \(\frac{\partial f}{\partial x_j}\) exists at \(x_0\), and that
\[
    \frac{\partial f}{\partial x_j}(x_0) = D_{e_j} f(x_0) = - D_{-e_j} f(x_0) = f'(x_0)(e_j).
\]
Also, if \(v = (v_1, \dots, v_n) = \sum_{j = 1}^n v_j e_j\), then we have
\[
    D_v f(x_0) = f'(x_0) \bigg(\sum_{j = 1}^n v_j e_j\bigg) = \sum_{j = 1}^n v_j f'(x_0)(e_j)
\]
(since \(f'(x_0)\) is linear) and thus
\[
    D_v f(x_0) = \sum_{j = 1}^n v_j \frac{\partial f}{\partial x_j}(x_0).
\]
Thus one can write directional derivatives in terms of partial derivatives, \emph{provided that} the function is actually differentiable at that point.
\end{additional corollary}

\begin{note}
    Just because the partial derivatives exist at a point \(x_0\), we cannot conclude that the function is differentiable there (Exercise \ref{ex 6.3.3}).
    However, if we know that the partial derivatives not only exist, but are continuous, then we can in fact conclude differentiability, thanks to the Theorem \ref{6.3.8}
\end{note}

\begin{theorem}\label{6.3.8}
    Let \(E\) be a subset of \(\mathbf{R}^n\), \(f : E \to \mathbf{R}^m\) be a function, \(F\) be a subset of \(E\), and \(x_0\) be an interior point of \(F\).
    If all the partial derivatives \(\frac{\partial f}{\partial x_j}\) exist on \(F\) and are continuous at \(x_0\), then \(f\) is differentiable at \(x_0\), and the linear transformation \(f'(x_0) : \mathbf{R}^n \to \mathbf{R}^m\) is defined by
    \[
        f'(x_0)\big((v_j)_{1 \leq j \leq n}\big) = \sum_{j = 1}^n v_j \frac{\partial f}{\partial x_j}(x_0).
    \]
\end{theorem}

\begin{proof}
    Let \(L : \mathbf{R}^n \to \mathbf{R}^m\) be the linear transformation
    \[
        L\big((v_j)_{1 \leq j \leq n}\big) \coloneqq \sum_{j = 1}^n v_j \frac{\partial f}{\partial x_j}(x_0).
    \]
    We have to prove that
    \[
        \lim_{x \to x_0 ; x \in E \setminus \{x_0\}} \frac{\norm*{f(x) - \big(f(x_0) + L(x - x_0)\big)}}{\norm*{x - x_0}} = 0.
    \]
    Let \(\varepsilon > 0\).
    It will suffice to find a radius \(\delta > 0\) such that
    \[
        \frac{\norm*{f(x) - \big(f(x_0) + L(x - x_0)\big)}}{\norm*{x - x_0}} \leq \varepsilon
    \]
    for all \(x \in B_{(\mathbf{R}^n, d_{l^2})}(x_0, \delta) \setminus \{x_0\}\).
    Equivalently, we wish to show that
    \[
        \norm*{f(x) - f(x_0) - L(x - x_0)} \leq \varepsilon \norm*{x - x_0}
    \]
    for all \(x \in B_{(\mathbf{R}^n, d_{l^2})}(x_0, \delta) \setminus \{x_0\}\).

    Because \(x_0\) is an interior point of \(F\), there exists a ball \(B_{(\mathbf{R}^n, d_{l^2})}(x_0, r)\) which is contained inside \(F\).
    Because each partial derivative \(\frac{\partial f}{\partial x_j}\) exists on \(F\) and is continuous at \(x_0\), there thus exists an \(0 < \delta_j < r\) such that \(\norm*{\frac{\partial f}{\partial x_j}(x) - \frac{\partial f}{\partial x_j}(x_0)} \leq \frac{\varepsilon}{nm}\) for every \(x \in B_{(\mathbf{R}^n, d_{l^2})}(x_0, \delta_j)\).
    If we take \(\delta = \min(\delta_1, \dots, \delta_n)\), then we thus have \(\norm*{\frac{\partial f}{\partial x_j}(x) - \frac{\partial f}{\partial x_j}(x_0)} \leq \frac{\varepsilon}{nm}\) for every \(x \in B_{(\mathbf{R}^n, d_{l^2})}(x_0, \delta)\) and every \(1 \leq j \leq n\).

    Let \(x \in B_{(\mathbf{R}^n, d_{l^2})}(x_0, \delta)\).
    We write \(x = x_0 + v_1 e_1 + v_2 e_2 + \dots + v_n e_n\) for some scalars \(v_1, \dots, v_n\).
    Note that
    \[
        \norm*{x - x_0} = \sqrt{v_1^2 + v_2^2 + \dots + v_n^2}
    \]
    and in particular we have \(\abs*{v_j} \leq \norm*{x - x_0}\) for all \(1 \leq j \leq n\).
    Our task is to show that
    \[
        \norm*{f(x_0 + v_1 e_1 + \dots + v_n e_n) - f(x_0) - \sum_{j = 1}^n v_j \frac{\partial f}{\partial x_j}(x_0)} \leq \varepsilon \norm*{x - x_0}.
    \]
    Write \(f\) in components as \(f = (f_1 , f_2, \dots, f_m)\)
    (so each \(f_i\) is a function from \(E\) to \(\mathbf{R}\)).
    From the mean value theorem in the \(x_1\) variable, we see that
    \[
        f_i(x_0 + v_1 e_1) - f_i(x_0) = \frac{\partial f_i}{\partial x_1}(x_0 + t_i e_1) v_1
    \]
    for some \(t_i\) between \(0\) and \(v_1\).
    But we have
    \[
        \abs*{\frac{\partial f_i}{\partial x_j}(x_0 + t_i e_1) - \frac{\partial f_i}{\partial x_j}(x_0)} \leq \norm*{\frac{\partial f}{\partial x_j}(x_0 + t_i e_1) - \frac{\partial f}{\partial x_j}(x_0)} \leq \frac{\varepsilon}{nm}
    \]
    and hence
    \[
        \abs*{f_i(x_0 + v_1 e_1) - f_i(x_0) - \frac{\partial f_i}{\partial x_1}(x_0) v_1} \leq \frac{\varepsilon \abs*{v_1}}{nm}.
    \]
    Summing this over all \(1 \leq i \leq m\) (and noting that \(\norm*{(y_1, \dots, y_m)} \leq \abs*{y_1} + \dots + \abs*{y_m}\) from the triangle inequality) we obtain
    \[
        \norm*{f(x_0 + v_1 e_1) - f(x_0) - \frac{\partial f}{\partial x_1}(x_0) v_1} \leq \frac{\varepsilon \abs*{v_1}}{n};
    \]
    since \(\abs*{v_1} \leq \norm*{x - x_0}\), we thus have
    \[
        \norm*{f(x_0 + v_1 e_1) - f(x_0) - \frac{\partial f}{\partial x_1}(x_0) v_1} \leq \frac{\varepsilon \norm*{x - x_0}}{n}.
    \]
    A similar argument gives
    \[
        \norm*{f(x_0 + v_1 e_1 + v_2 e_2) - f(x_0 + v_1 e_1) - \frac{\partial f}{\partial x_2}(x_0) v_2} \leq \frac{\varepsilon \norm*{x - x_0}}{n}
    \]
    and so forth up to
    \begin{align*}
         & \norm*{f(x_0 + v_1 e_1 + \dots + v_n e_n) - f(x_0 + v_1 e_1 + \dots + v_{n - 1} e_{n - 1}) - \frac{\partial f}{\partial x_n}(x_0) v_n} \\
         & \leq \frac{\varepsilon \norm*{x - x_0}}{n}.
    \end{align*}
    If we sum these \(n\) inequalities and use the triangle inequality \(\norm*{x + y} \leq \norm*{x} + \norm*{y}\), we obtain a telescoping series which simplifies to
    \[
        \norm*{f(x_0 + v_1 e_1 + \dots + v_n e_n) - f(x_0) - \sum_{j = 1}^n \frac{\partial f}{\partial x_j}(x_0) v_j} \leq \varepsilon \norm*{x - x_0}
    \]
    as desired.
\end{proof}

\begin{additional corollary}\label{ac 6.3.3}
From Theorem \ref{6.3.8} and Lemma \ref{6.3.5} we see that if the partial derivatives of a function \(f : E \to \mathbf{R}^m\) exist and are continuous on some set \(F\), then all the directional derivatives also exist at every interior point \(x_0\) of \(F\), and we have the formula
\[
    D_{(v_1, \dots, v_n)} f(x_0) = \sum_{j = 1}^n v_j \frac{\partial f}{\partial x_j}(x_0).
\]
In particular, if \(f : E \to \mathbf{R}\) is a real-valued function, and we define the \emph{gradient} \(\nabla f(x_0)\) of \(f\) at \(x_0\) to be the \(n\)-dimensional row vector
\[
    \nabla f(x_0) \coloneqq \bigg(\frac{\partial f}{\partial x_1}(x_0), \dots, \frac{\partial f}{\partial x_n}(x_0)\bigg),
\]
then we have the familiar formula
\[
    D_v f(x_0) = v \cdot \nabla f(x_0)
\]
whenever \(x_0\) is in the interior of the region where the gradient exists and is continuous.
\end{additional corollary}

\begin{additional corollary}\label{ac 6.3.4}
More generally, if \(f : E \to \mathbf{R}^m\) is a function taking values in \(\mathbf{R}^m\), with \(f = (f_1, \dots, f_m)\), and \(x_0\) is in the interior of the region where the partial derivatives of \(f\) exist and are continuous, then we have from Theorem \ref{6.3.8} that
\[
    f'(x_0)\big((v_j)_{1 \leq j \leq n}\big) = \sum_{j = 1}^n v_j \frac{\partial f}{\partial x_j}(x_0) = \bigg(\sum_{j = 1}^n v_j \frac{\partial f_i}{\partial x_j}(x_0)\bigg)_{1 \leq i \leq m},
\]
which we can rewrite as
\[
    L_{D f(x_0)}\big((v_j)_{1 \leq j \leq n}\big)
\]
where \(D f(x_0)\) is the \(m \times n\) matrix
\begin{align*}
    D f(x_0) & \coloneqq \bigg(\frac{\partial f_i}{\partial x_j}(x_0)\bigg)_{1 \leq i \leq m ; 1 \leq j \leq n} \\
             & = \begin{pmatrix}
        \frac{\partial f_1}{\partial x_1}(x_0) & \frac{\partial f_1}{\partial x_2}(x_0) & \dots  & \frac{\partial f_1}{\partial x_n}(x_0) \\
        \frac{\partial f_2}{\partial x_1}(x_0) & \frac{\partial f_2}{\partial x_2}(x_0) & \dots  & \frac{\partial f_2}{\partial x_n}(x_0) \\
        \vdots                                 & \vdots                                 & \ddots & \vdots                                 \\
        \frac{\partial f_m}{\partial x_1}(x_0) & \frac{\partial f_m}{\partial x_2}(x_0) & \dots  & \frac{\partial f_m}{\partial x_n}(x_0)
    \end{pmatrix}.
\end{align*}
Thus we have
\[
    \big(D_v f(x_0)\big)^\top = \big(f'(x_0)(v)\big)^\top = D f(x_0) v^\top.
\]

The matrix \(D f(x_0)\) is sometimes also called the \emph{derivative matrix} or \emph{differential matrix} of \(f\) at \(x_0\), and is closely related to the total derivative \(f'(x_0)\).
One can also write \(Df\) as
\[
    D f(x_0) = \bigg(\frac{\partial f}{\partial x_1}(x_0)^\top, \frac{\partial f}{\partial x_2}(x_0)^\top, \dots, \frac{\partial f}{\partial x_n}(x_0)^\top\bigg),
\]
i.e., each of the columns of \(D f(x_0)\) is one of the partial derivatives of \(f\), expressed as a column vector.
Or one could write
\[
    D f(x_0) = \begin{pmatrix}
        \nabla f_1(x_0) \\
        \nabla f_2(x_0) \\
        \vdots          \\
        \nabla f_m(x_0) \\
    \end{pmatrix}
\]
i.e., the rows of \(D f(x_0)\) are the gradient of various components of \(f\).
In particular, if \(f\) is scalar-valued (i.e., \(m = 1\)), then \(Df\) is the same as \(\nabla f\).
\end{additional corollary}

\exercisesection

\begin{exercise}\label{ex 6.3.1}
    Prove Lemma \ref{6.3.5}.
\end{exercise}

\begin{proof}
    See Lemma \ref{6.3.5}.
\end{proof}

\begin{exercise}\label{ex 6.3.2}
    Let \(E\) be a subset of \(\mathbf{R}^n\), let \(f : E \to \mathbf{R}^m\) be a function, let \(x_0\) be an interior point of \(E\), and let \(1 \leq j \leq n\).
    Show that \(\frac{\partial f}{\partial x_j}(x_0)\) exists if and only if \(D_{e_j} f(x_0)\) and \(D_{-e_j} f(x_0)\) exist and are negatives of each other
    (thus \(D_{e_j} f(x_0) = -D_{-e_j} f(x_0)\));
    furthermore, one has \(\frac{\partial f}{\partial x_j}(x_0) = D_{e_j} f(x_0)\) in this case.
\end{exercise}

\begin{proof}
    We have
    \begin{align*}
         & \frac{\partial f}{\partial x_j}(x_0)                                                                                           \\
         & = \lim_{t \to 0 ; t \neq 0, x_0 + t e_j \in E} \frac{f(x_0 + t e_j) - f(x_0)}{t} & \text{(by Definition \ref{6.3.7})}          \\
         & = \begin{cases}
            \lim_{t \to 0 ; t > 0, x_0 + t e_j \in E} \frac{f(x_0 + t e_j) - f(x_0)}{t} \\
            \lim_{t \to 0 ; t < 0, x_0 + t e_j \in E} \frac{f(x_0 + t e_j) - f(x_0)}{t}
        \end{cases}                                                     & \text{(by Proposition 9.5.3 in Analysis I)} \\
         & = \begin{cases}
            \lim_{t \to 0 ; t > 0, x_0 + t e_j \in E} \frac{f(x_0 + t e_j) - f(x_0)}{t} \\
            \lim_{t \to 0 ; t > 0, x_0 + t e_j \in E} \frac{f(x_0 - t e_j) - f(x_0)}{-t}
        \end{cases}                                                                                                   \\
         & = \begin{cases}
            \lim_{t \to 0 ; t > 0, x_0 + t e_j \in E} \frac{f(x_0 + t e_j) - f(x_0)}{t} \\
            -\lim_{t \to 0 ; t > 0, x_0 + t e_j \in E} \frac{f\big(x_0 + t (-e_j)\big) - f(x_0)}{t}
        \end{cases}                                                                                                   \\
         & = \begin{cases}
            D_{e_j} f(x_0) \\
            - D_{-e_j} f(x_0)
        \end{cases}.                                                    & \text{(by Definition \ref{6.3.1})}
    \end{align*}
\end{proof}

\begin{exercise}\label{ex 6.3.3}
    Let \(f : \mathbf{R}^2 \to \mathbf{R}\) be the function defined by \(f(x, y) \coloneqq \frac{x^3}{x^2 + y^2}\) when \((x, y) \neq (0, 0)\), and \(f(0, 0) \coloneqq 0\).
    Show that \(f\) is not differentiable at \((0, 0)\), despite being differentiable in every direction \(v \in \mathbf{R}^2\) at \((0, 0)\).
    Explain why this does not contradict Theorem \ref{6.3.8}.
\end{exercise}

\begin{proof}
    First we show that \(f\) is differentiable in every direction \(v \in \mathbf{R}^2\) at \((0, 0)\).
    Since
    \begin{align*}
        \forall\ v \in \mathbf{R} \setminus \{(0, 0)\}, & \lim_{t \to 0 ; t > 0, (0, 0) + tv \in \mathbf{R}^2} \frac{f\big((0, 0) + tv\big) - f(0, 0)}{t}    \\
                                                        & = \lim_{t \to 0 ; t > 0, (0, 0) + tv \in \mathbf{R}^2} \frac{f(tv)}{t}                             \\
                                                        & = \lim_{t \to 0 ; t > 0, (0, 0) + tv \in \mathbf{R}^2} \frac{t^3 v_1^3}{(t^2 v_1^2 + t^2 v_2^2) t} \\
                                                        & = \lim_{t \to 0 ; t > 0, (0, 0) + tv \in \mathbf{R}^2} \frac{v_1^3}{v_1^2 + v_2^2}                 \\
                                                        & = \frac{v_1^3}{v_1^2 + v_2^2}
    \end{align*}
    and
    \begin{align*}
         & \lim_{t \to 0 ; t > 0, (0, 0) + t (0, 0) \in \mathbf{R}^2} \frac{f\big((0, 0) + t(0, 0)\big) - f(0, 0)}{t} \\
         & = \lim_{t \to 0 ; t > 0, (0, 0) + t (0, 0) \in \mathbf{R}^2} 0                                             \\
         & = 0,
    \end{align*}
    by Definition \ref{6.3.1} we know that \(f\) is differentiable in every direction \(v \in \mathbf{R}^2\) at \((0, 0)\).

    Next we show that \(f\) is not differentiable at \((0, 0)\).
    Suppose for sake of contradiction that \(f\) is differentiable at \((0, 0)\).
    Then by Additional Corollary \ref{ac 6.3.2} we know that
    \[
        \forall\ v \in \mathbf{R}^2, D_v f(0, 0) = f'(0, 0)(v) = \sum_{i = 1}^2 v_i f'(0, 0)(e_i).
    \]
    But
    \[
        f'(0, 0)(1, 1) = \frac{1^3}{1^2 + 1^2} = \frac{1}{2}
    \]
    is not equal to
    \[
        \sum_{i = 1}^2 1 f'(0, 0)(e_i) = f'(0, 0)\big((1, 0)\big) + f'(0, 0)\big((0, 1)\big) = \frac{1^3}{1^2 + 0^2} + \frac{0^3}{0^2 + 1^2} = 1,
    \]
    a contradiction.
    Thus \(f\) is not differentiable at \((0, 0)\).

    Now we show that this does not contradict Theorem \ref{6.3.8}.
    We claim that \(\frac{\partial f}{\partial x}\) is not continuous at \((0, 0)\).
    Since
    \[
        D_{e_1} f(0, 0) = \frac{1^3}{1^2 + 0^2} = 1 = -\frac{(-1)^3}{(-1)^2 + 0^2} = -D_{-e_1} f(0, 0),
    \]
    by Exercise \ref{ex 6.3.2} we know that \(\frac{\partial f}{\partial x}(0, 0) = 1\).
    But for each \((x_0, y_0) \in \mathbf{R}^2 \setminus \{(0, 0)\}\), we have
    \begin{align*}
         & = \frac{\partial f}{\partial x}(x_0, y_0)                                                                                                                                                                                              \\
         & = \lim_{t \to 0 ; t \neq 0, (x_0, y_0) + t(1, 0) \in \mathbf{R}^2} \frac{f\big((x_0, y_0) + t(1, 0)\big) - f(x_0, y_0)}{t}                                                                                                             \\
         & = \lim_{t \to 0 ; t \neq 0, (x_0, y_0) + t(1, 0) \in \mathbf{R}^2} \frac{f(x_0 + t, y_0) - f(x_0, y_0)}{t}                                                                                                                             \\
         & = \lim_{t \to 0 ; t \neq 0, (x_0, y_0) + t(1, 0) \in \mathbf{R}^2} \frac{\frac{(x_0 + t)^3}{(x_0 + t)^2 + y_0^2} - \frac{x_0^3}{x_0^2 + y_0^2}}{t}                                                                                     \\
         & = \lim_{t \to 0 ; t \neq 0, (x_0, y_0) + t(1, 0) \in \mathbf{R}^2} \frac{(x_0 + t)^3 (x_0^2 + y_0^2) - x_0^3 \big((x_0 + t)^2 + y_0^2\big)}{t \big((x_0 + t)^2 + y_0^2\big) (x_0^2 + y_0^2)}                                           \\
         & = \lim_{t \to 0 ; t \neq 0, (x_0, y_0) + t(1, 0) \in \mathbf{R}^2} \frac{(x_0^3 + 3 x_0^2 t + 3 x_0 t^2 + t^3) (x_0^2 + y_0^2) - x_0^3 (x_0^2 + 2 t x_0 + t^2 + y_0^2)}{t (x_0^2 + 2 t x_0 + t^2 + y_0^2) (x_0^2 + y_0^2)}             \\
         & = \lim_{t \to 0 ; t \neq 0, (x_0, y_0) + t(1, 0) \in \mathbf{R}^2} \frac{(3 x_0^2 + 3 x_0 t + t^2) (x_0^2 + y_0^2) - x_0^3 (2 x_0 + t)}{(x_0^2 + 2 t x_0 + t^2 + y_0^2) (x_0^2 + y_0^2)}                                               \\
         & = \lim_{t \to 0 ; t \neq 0, (x_0, y_0) + t(1, 0) \in \mathbf{R}^2} \frac{x_0^4 + 2 t x_0^3 + t^2 x_0^2 + 3 x_0^2 y_0^2 + 3 t x_0 y_0^2 + t^2 y_0^2}{x_0^4 + 2 t x_0^3 + t^2 x_0^2 + 2 x_0^2 y_0^2 + 2 t x_0 y_0^2 + t^2 y_0^2 + y_0^4} \\
         & = \frac{x_0^4 + 3 x_0^2 y_0^2}{x_0^4 + 2 x_0^2 y_0^2 + y_0^4}.
    \end{align*}
    Thus we see that \((x_0, y_0) \to (0, 0)\) implies \(\frac{\partial f}{\partial x}(x_0, y_0) \not\to 1\), which means \(\frac{\partial f}{\partial x}\) is not continuous at \((0, 0)\).
\end{proof}

\begin{exercise}\label{ex 6.3.4}
    Let \(f : \mathbf{R}^n \to \mathbf{R}^m\) be a differentiable function such that \(f'(x) = 0\) for all \(x \in \mathbf{R}^n\).
    Show that \(f\) is constant.
    For a tougher challenge, replace the domain \(\mathbf{R}^n\) by an open connected subset \(\Omega\) of \(\mathbf{R}^n\).
\end{exercise}